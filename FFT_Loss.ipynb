{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Noah's Code"
      ],
      "metadata": {
        "id": "bHKcrzvSfwkN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "2p4lW19dwVYT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import torch\n",
        "def torch_autocorr(x):\n",
        "    if len(x.shape) < 4:\n",
        "        x = torch.unsqueeze(x, dim=0)\n",
        "\n",
        "    x = x.detach().cpu().numpy()\n",
        "\n",
        "    dim = x.shape[1]\n",
        "\n",
        "    x = 2*x - 1\n",
        "    x = tf.transpose(x, perm=[0, 3, 1, 2])\n",
        "    x = tf.cast(x, tf.complex64)\n",
        "\n",
        "    m = x\n",
        "    M = np.array(tf.signal.fft2d(m))\n",
        "\n",
        "    mag = tf.math.abs(M)\n",
        "    mag = tf.cast(mag, tf.complex64)\n",
        "\n",
        "    ang = tf.math.atan2(tf.math.imag(M), tf.math.real(M))\n",
        "    ang = tf.cast(ang, tf.complex64)\n",
        "\n",
        "    exp1 = tf.math.exp(tf.dtypes.complex(0., -1.)*ang)\n",
        "    exp2 = tf.math.exp(tf.dtypes.complex(0., 1.)*ang)\n",
        "\n",
        "    term1 = mag*exp1\n",
        "    term2 = mag*exp2\n",
        "\n",
        "    FFtmp = (term1*term2)/(32**2)\n",
        "\n",
        "    autocorr = tf.signal.ifft2d(FFtmp)\n",
        "    autocorr = tf.math.real(autocorr)\n",
        "\n",
        "    autocorr = tf.transpose(autocorr, perm=[0, 2, 3, 1])\n",
        "\n",
        "    rv = np.int32(np.floor(dim/2))\n",
        "    #rv = tf.cast(tf.math.floor(dim/2), tf.int32)\n",
        "    # autocorr = tf.roll(autocorr, rv, 1)\n",
        "    autocorr = tf.roll(autocorr, rv, 2)\n",
        "    # # autocorr = tf.signal.ifftshift(autocorr, axes=(1, 2))\n",
        "\n",
        "\n",
        "    # # Convert the TensorFlow tensor to a NumPy array\n",
        "    # np_array = autocorr.numpy()\n",
        "    np_array = autocorr.numpy()\n",
        "    # Create a PyTorch tensor from the NumPy array\n",
        "    torch_tensor_autocorr = torch.from_numpy(np_array)\n",
        "\n",
        "    return torch_tensor_autocorr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Torch"
      ],
      "metadata": {
        "id": "bEM5xpVDgDd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def autocorr(x):\n",
        "    \"\"\"\n",
        "    x is a 3 dimensional torch tensor. \n",
        "    \"\"\"\n",
        "    if len(x.shape) < 4:\n",
        "        x = torch.unsqueeze(x, dim=0)\n",
        "\n",
        "    dim = x.shape[1]\n",
        "\n",
        "    x = 2*x - 1\n",
        "    x = torch.permute(x, (0, 3, 1, 2))\n",
        "    x_complex = x.type(torch.complex64)\n",
        "\n",
        "    M = torch.fft.fft2(x_complex)\n",
        "    mag_M_complex = torch.abs(M).type(torch.complex64)\n",
        "\n",
        "    ang = torch.atan2(M.imag, M.real)\n",
        "    ang = ang.type(torch.complex64)\n",
        "\n",
        "    exp1 = torch.exp(torch.complex(torch.tensor([0], dtype=torch.float32), torch.tensor([-1], dtype=torch.float32))*ang)\n",
        "    exp2 = torch.exp(torch.complex(torch.tensor([0], dtype=torch.float32), torch.tensor([1], dtype=torch.float32))*ang)\n",
        "\n",
        "    term1 = mag_M_complex*exp1\n",
        "    term2 = mag_M_complex*exp2\n",
        "\n",
        "    FFtmp = (term1*term2) / (32**2)\n",
        "\n",
        "    autocorr = torch.fft.ifft2(FFtmp) # till here the values are the same upto 1e-7 tolerance\n",
        "    autocorr = autocorr.real\n",
        "    autocorr = torch.permute(autocorr, (0, 2, 3, 1))\n",
        "\n",
        "    rv = torch.tensor(dim//2, dtype=torch.int32)\n",
        "    # #autocorr = torch.roll(autocorr, rv, 1)\n",
        "    # #autocorr = torch.roll(autocorr, rv, 2)\n",
        "    autocorr = torch.roll(autocorr, dim//2, 2)\n",
        "    # return autocorr\n",
        "\n",
        "    return autocorr    "
      ],
      "metadata": {
        "id": "pLY6MJoRx-Wk"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### testing code"
      ],
      "metadata": {
        "id": "SdtPZwTggH0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = torch.randn((3, 64, 64))\n",
        "tolerance = 1e-07\n",
        "def equal_within_tolerance(arr1, arr2, ):\n",
        "    return np.isclose(arr1.numpy(), arr2.numpy(), \n",
        "                      atol=tolerance\n",
        "                      )"
      ],
      "metadata": {
        "id": "faQVzZmo0na5"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output1 = torch_autocorr(test_input)\n",
        "output2 = autocorr(test_input)\n",
        "print(output1.shape)\n",
        "print(output2.shape)\n",
        "print(f\"All values equal: {(output1==output2).all()}\")\n",
        "print(equal_within_tolerance(output1, output2))\n",
        "print(f\"All values within the tolerance of {tolerance}: {equal_within_tolerance(output1, output2).all()}\")\n",
        "print(f\"{np.sum((equal_within_tolerance(output1, output2))==True)} values within the tolerance value of {tolerance}.\")\n",
        "print(f\"{np.sum((equal_within_tolerance(output1, output2))==False)} not values within the tolerance value {tolerance}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgG06qTh1reX",
        "outputId": "b5799a7d-a25b-4604-caa3-8470a6915b87"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 64, 64])\n",
            "torch.Size([1, 3, 64, 64])\n",
            "All values equal: False\n",
            "[[[[ True  True  True ...  True  True  True]\n",
            "   [ True  True  True ...  True  True  True]\n",
            "   [ True  True  True ...  True  True  True]\n",
            "   ...\n",
            "   [ True  True  True ...  True  True  True]\n",
            "   [ True  True  True ...  True  True  True]\n",
            "   [ True  True  True ...  True  True  True]]\n",
            "\n",
            "  [[ True  True  True ...  True  True  True]\n",
            "   [ True  True  True ...  True  True  True]\n",
            "   [ True  True  True ...  True  True  True]\n",
            "   ...\n",
            "   [ True  True  True ...  True  True  True]\n",
            "   [ True  True  True ...  True  True  True]\n",
            "   [ True  True  True ...  True  True  True]]\n",
            "\n",
            "  [[ True  True  True ...  True  True  True]\n",
            "   [ True  True  True ...  True  True  True]\n",
            "   [ True  True  True ...  True  True  True]\n",
            "   ...\n",
            "   [ True  True  True ...  True  True  True]\n",
            "   [ True  True  True ...  True  True  True]\n",
            "   [ True  True  True ...  True  True  True]]]]\n",
            "All values within the tolerance of 1e-07: False\n",
            "12285 values within the tolerance value of 1e-07.\n",
            "3 not values within the tolerance value 1e-07.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Definition"
      ],
      "metadata": {
        "id": "LqVwZnkCBP_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FFTLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FFTLoss, self).__init__()\n",
        "        self.mae_loss = nn.L1Loss()\n",
        "    \n",
        "    def forward(self, input, target):\n",
        "        input_autocorr = autocorr(input)\n",
        "        target_autocorr = autocorr(target)\n",
        "        diff = self.mae_loss(input_autocorr, target_autocorr)\n",
        "        return diff"
      ],
      "metadata": {
        "id": "9QYLYg3qBJsB"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the loss\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input = torch.randn((3, 64, 64), requires_grad=True)\n",
        "target = torch.randn((3, 64, 64))\n",
        "\n",
        "mae_loss = nn.L1Loss()\n",
        "output = mae_loss(input, target)\n",
        "output.backward()\n",
        "\n",
        "print('input: ', input)\n",
        "print('target: ', target)\n",
        "print('output: ', output)"
      ],
      "metadata": {
        "id": "kmgs_n1awjq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c72e386-f7cf-4453-8f2e-08c7836fb803"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  tensor([[[ 0.7833,  1.7424,  0.8350,  ...,  0.7731,  0.2165,  0.2028],\n",
            "         [-0.3478, -0.4437, -1.7366,  ..., -1.1579, -0.9653, -0.7782],\n",
            "         [-0.5331, -0.7700,  0.3380,  ...,  0.3561,  0.0362,  1.5044],\n",
            "         ...,\n",
            "         [-0.1079,  1.8757, -0.0354,  ...,  1.7489, -2.1834,  1.2323],\n",
            "         [ 0.4964, -1.0542,  0.6126,  ...,  1.3857,  2.0068, -0.9700],\n",
            "         [ 1.5098, -0.2395, -1.3822,  ...,  1.2966,  0.2667, -0.0671]],\n",
            "\n",
            "        [[ 0.6029, -1.5645,  0.8020,  ...,  0.0533, -0.7314,  0.7086],\n",
            "         [ 0.2386, -1.9438,  3.0096,  ..., -0.3898, -1.2965, -0.1086],\n",
            "         [-0.7281,  0.9692,  0.8955,  ..., -0.0182,  1.1141, -0.5534],\n",
            "         ...,\n",
            "         [-0.3685, -0.7304, -0.3284,  ..., -1.7926, -1.2779,  0.2217],\n",
            "         [ 2.0750, -1.1924, -0.2329,  ..., -0.4250, -0.1801,  1.2846],\n",
            "         [-0.7208,  0.8995,  1.3209,  ..., -0.2966,  1.9810,  1.6138]],\n",
            "\n",
            "        [[ 0.2652, -0.7919,  0.5994,  ..., -1.2554, -1.4385,  2.0571],\n",
            "         [ 0.1718, -0.7977,  0.4268,  ...,  1.5792,  0.3637,  0.8397],\n",
            "         [ 0.4209,  1.5336,  0.7162,  ...,  1.5801,  1.1566, -1.5586],\n",
            "         ...,\n",
            "         [-0.6860, -0.8151,  0.5924,  ...,  0.0061, -0.8636,  1.8551],\n",
            "         [ 0.6250,  2.5113,  2.1331,  ...,  0.2898, -0.3031,  1.0146],\n",
            "         [ 0.9146,  0.0059, -1.2928,  ...,  2.0975,  0.4775, -0.0308]]],\n",
            "       requires_grad=True)\n",
            "target:  tensor([[[ 1.4098, -0.6663,  1.0166,  ...,  1.2387, -0.1123,  0.1143],\n",
            "         [-0.0919,  1.4388,  0.9849,  ...,  0.5178,  1.2602,  0.9986],\n",
            "         [ 0.6042,  1.0525,  1.9657,  ..., -2.1645,  0.5200,  0.2170],\n",
            "         ...,\n",
            "         [-0.0605, -0.3276, -1.4321,  ...,  1.5855, -0.3788, -0.3353],\n",
            "         [-0.5247, -0.0108,  2.2796,  ..., -0.4507, -1.0480, -0.5805],\n",
            "         [ 0.9293,  1.8214,  0.1696,  ...,  0.3125, -1.2852,  1.2483]],\n",
            "\n",
            "        [[-0.5334, -0.0166,  1.2446,  ..., -0.9648, -0.9580, -0.1221],\n",
            "         [ 0.2740,  0.1659, -1.7332,  ..., -0.8715,  0.7242, -0.2267],\n",
            "         [ 0.4939, -0.3387, -0.9524,  ..., -0.7408, -0.0407,  1.7655],\n",
            "         ...,\n",
            "         [-0.1380, -0.4415, -1.5989,  ...,  0.4448, -0.8762, -0.4838],\n",
            "         [ 0.5181,  0.4931,  0.2615,  ...,  1.8364,  1.1044, -1.2639],\n",
            "         [-0.2816,  0.0871,  0.2033,  ...,  0.6464, -1.3326, -1.1567]],\n",
            "\n",
            "        [[ 0.6064, -0.4992,  0.8355,  ..., -0.2499, -0.3001, -0.4280],\n",
            "         [ 0.4499, -1.4580,  0.4414,  ...,  0.0978, -0.0562,  0.1021],\n",
            "         [-0.9394,  0.3404,  0.4612,  ..., -1.5432, -0.2337,  1.0641],\n",
            "         ...,\n",
            "         [ 2.3648,  2.4773,  1.0061,  ..., -0.2271,  0.5129, -3.6023],\n",
            "         [-0.4602, -1.0043,  2.1728,  ..., -0.0234, -1.0356, -0.9200],\n",
            "         [-0.2032, -1.5550,  1.0775,  ...,  0.0959, -0.6928,  1.0221]]])\n",
            "output:  tensor(1.1405, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the loss\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input = torch.randn((3, 64, 64), requires_grad=True)\n",
        "target = torch.randn((3, 64, 64))\n",
        "\n",
        "fft_loss = FFTLoss()\n",
        "output = fft_loss(input, target)\n",
        "output.backward()\n",
        "\n",
        "print('input: ', input)\n",
        "print('target: ', target)\n",
        "print('output: ', output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p0Q1mCwCrc3",
        "outputId": "8168ccd8-269e-42cc-9b0a-071a776fa7da"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  tensor([[[-0.6055, -0.3839,  0.4894,  ..., -1.5995, -1.0831, -0.6098],\n",
            "         [ 0.1162, -0.9619, -0.0865,  ..., -0.4587, -0.4353, -0.6610],\n",
            "         [ 0.8993, -2.2511,  1.5225,  ..., -1.8125,  0.0825, -0.3185],\n",
            "         ...,\n",
            "         [-0.2171, -0.6641, -2.8307,  ..., -0.0839,  0.0508, -0.9194],\n",
            "         [ 1.5035,  2.0641,  1.7570,  ..., -0.0079, -0.2611,  0.2861],\n",
            "         [-1.6612, -0.4720, -0.2615,  ...,  0.0289, -0.7971, -0.6313]],\n",
            "\n",
            "        [[ 1.1084, -0.2814, -1.5716,  ...,  0.1583,  0.3641,  1.0905],\n",
            "         [ 0.0252, -1.0436, -0.3290,  ...,  0.0718, -0.1969,  0.8435],\n",
            "         [-1.7029,  0.4927, -0.7195,  ...,  0.6377,  2.7637,  1.3378],\n",
            "         ...,\n",
            "         [-0.4161,  0.9680, -0.3302,  ..., -1.0823, -0.4520,  0.9102],\n",
            "         [-0.6099,  1.2596, -1.4773,  ...,  0.5926, -0.5569, -0.6325],\n",
            "         [ 0.6208,  0.6184,  0.4602,  ...,  0.6756, -0.4513,  0.4019]],\n",
            "\n",
            "        [[ 0.3724,  0.5834,  0.6066,  ...,  0.3487,  0.1162, -0.1470],\n",
            "         [ 1.3664, -0.6699, -0.5641,  ...,  1.2000, -1.2983, -0.5592],\n",
            "         [-0.4821, -0.6623, -0.0505,  ...,  0.0622,  0.2483, -0.5436],\n",
            "         ...,\n",
            "         [ 0.4938, -0.3928,  0.7865,  ...,  0.0050, -0.3179, -0.7640],\n",
            "         [-0.8931,  1.0252, -0.6371,  ..., -0.4099,  0.2035,  0.8642],\n",
            "         [-0.3133,  0.0529,  1.9753,  ..., -0.6736,  1.0267, -0.3796]]],\n",
            "       requires_grad=True)\n",
            "target:  tensor([[[-0.1277, -0.1734, -0.2230,  ...,  3.8501, -0.4269, -1.0863],\n",
            "         [ 1.0272,  0.5290, -0.5338,  ..., -1.4826,  0.9706,  0.7602],\n",
            "         [-0.1518,  0.5018, -0.1730,  ...,  0.2395,  0.0738,  1.1676],\n",
            "         ...,\n",
            "         [ 1.0506, -0.6799,  0.9122,  ...,  0.0047,  0.1221,  1.2682],\n",
            "         [-0.2580, -0.1882, -1.4383,  ...,  0.4813, -1.0511,  2.9999],\n",
            "         [ 1.4056, -1.1147,  0.3476,  ...,  0.8944,  0.2997, -0.4700]],\n",
            "\n",
            "        [[ 0.3824,  0.0297,  0.2952,  ..., -0.2379,  0.2469, -1.7652],\n",
            "         [-1.0898, -0.7263,  1.5034,  ..., -0.7127,  1.0533, -0.2713],\n",
            "         [ 0.2943, -1.1680,  0.4875,  ..., -1.2315,  0.6488, -0.7898],\n",
            "         ...,\n",
            "         [-2.3613,  0.8453, -1.5626,  ..., -0.0302,  0.4264, -0.2892],\n",
            "         [-2.0030,  0.9535,  0.4382,  ..., -1.6916,  0.9231,  0.3594],\n",
            "         [ 1.0478,  0.4069,  0.2123,  ..., -0.9071,  0.4739,  0.6010]],\n",
            "\n",
            "        [[ 1.2354, -1.6931,  0.4341,  ..., -0.4808,  1.1584,  0.3703],\n",
            "         [ 1.1662, -0.3207,  2.2171,  ..., -1.0790, -1.1827, -0.4187],\n",
            "         [ 0.7223, -0.3321, -1.6621,  ...,  0.2327, -0.1306, -1.7772],\n",
            "         ...,\n",
            "         [ 0.4040,  1.0113, -1.3186,  ..., -0.5958,  0.6891,  0.0283],\n",
            "         [-0.1298,  0.9031,  1.1200,  ...,  0.2321,  0.5974,  1.0674],\n",
            "         [-2.7364,  0.3979,  0.3434,  ..., -1.0066, -0.6870,  0.4015]]])\n",
            "output:  tensor(0.0876, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    }
  ]
}